---
title: "Don’t Listen To Me: Understanding and Exploring Jailbreak Prompts of Large Language Models"
collection: publications
permalink: /publication/2024-08-14-USENIX-Jailbreak-12
excerpt: 'This paper is about investigating LLM jailbreak threats, from the perspective of empirical evaluation and automatic generation.'
date: 2024-08-14
venue: 'USENIX Security Symposium'
paperurl: 'https://zh1yu4nyu.github.io/files/ZhiyuanYu_CCS23_AntiFake.pdf'
# citation: 'Z. Yu, X. Liu, S. Liang, Z. Cameron, C. Xiao, N. Zhang. Don’t Listen To Me: Understanding and Exploring Jailbreak Prompts of Large Language Models. In Proceedings of the 33rd USENIX Security Symposium 2024. USENIX Association.'
---
This paper is about investigating LLM jailbreak threats, from the perspective of empirical evaluation and automatic generation.

[Download paper here](https://zh1yu4nyu.github.io/files/ZhiyuanYu_CCS23_AntiFake.pdf)

Recommended citation: Z. Yu, X. Liu, S. Liang, Z. Cameron, C. Xiao, N. Zhang. Don’t Listen To Me: Understanding and Exploring Jailbreak Prompts of Large Language Models. In Proceedings of the 33rd USENIX Security Symposium 2024. USENIX Association.